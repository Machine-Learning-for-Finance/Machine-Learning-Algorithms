{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Machine-Learning-for-Finance/Machine-Learning-Algorithms/blob/master/01-Data%20Loading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "veHdEGsVuCZk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import environ\n",
    "\n",
    "environ['TF_FORCE_GPU_ALLOW_GROWTH'] = \"true\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from utils import hello_world\n",
    "hello_world()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fQso5Qf1uPCs"
   },
   "source": [
    "# Loading From Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "Zg_Ml3XCuCZu",
    "outputId": "351b33f7-733d-43b2-921c-1826c93814bb"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    base_location = \"/content/drive/My Drive/data/\"\n",
    "except:\n",
    "    base_location = \"/data/FannieMae/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "a98Ks0awue5j",
    "outputId": "82fd6144-4e82-457c-ad27-8260001c599c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '/content/drive/My Drive/data/2010Q1': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls /content/drive/My\\ Drive/data/2010Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "51nuHFu2uCZx"
   },
   "source": [
    "# Financial Datasets\n",
    "\n",
    "There are a large number of financial datasets that are available, the first one we will discuss is the Fannie Mae Fixed Rate Mortgage Dataset.\n",
    "\n",
    "- https://www.fanniemae.com/portal/funding-the-market/data/loan-performance-data.html\n",
    "\n",
    "- https://loanperformancedata.fanniemae.com/lppub/index.html#Portfolio\n",
    "\n",
    "Which consists of both Acquisitions and Performance data for a collection of mortgages.\n",
    "\n",
    "To make our lives a bit easier here are the column names pulled from the provided `R` script to load the data.  See `R` is good for at least one thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSyctLHUuCZx"
   },
   "outputs": [],
   "source": [
    "AcquisitionColumnNames = (\n",
    "    \"LOAN_ID\", \"ORIG_CHN\", \"Seller.Name\", \n",
    "    \"ORIG_RT\", \"ORIG_AMT\", \"ORIG_TRM\", \"ORIG_DTE\",\n",
    "    \"FRST_DTE\", \"OLTV\", \"OCLTV\", \"NUM_BO\", \n",
    "    \"DTI\", \"CSCORE_B\", \"FTHB_FLG\", \"PURPOSE\", \n",
    "    \"PROP_TYP\", \"NUM_UNIT\", \"OCC_STAT\", \"STATE\", \"ZIP_3\", \n",
    "    \"MI_PCT\", \"Product.Type\", \"CSCORE_C\", \"MI_TYPE\", \n",
    "    \"RELOCATION_FLG\"\n",
    ")\n",
    "\n",
    "PerformanceColumnNames = (\n",
    "    \"LOAN_ID\", \"Monthly.Rpt.Prd\", \"Servicer.Name\", \n",
    "    \"LAST_RT\", \"LAST_UPB\", \"Loan.Age\", \"Months.To.Legal.Mat\", \n",
    "    \"Adj.Month.To.Mat\", \"Maturity.Date\", \"MSA\", \n",
    "    \"Delq.Status\", \"MOD_FLAG\", \"Zero.Bal.Code\", \n",
    "    \"ZB_DTE\", \"LPI_DTE\", \"FCC_DTE\",\"DISP_DT\", \n",
    "    \"FCC_COST\", \"PP_COST\", \"AR_COST\", \"IE_COST\", \n",
    "    \"TAX_COST\", \"NS_PROCS\",\"CE_PROCS\", \"RMW_PROCS\", \n",
    "    \"O_PROCS\", \"NON_INT_UPB\", \"PRIN_FORG_UPB_FHFA\", \n",
    "    \"REPCH_FLAG\", \"PRIN_FORG_UPB_OTH\", \"TRANSFER_FLG\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "keiHB79QuCZ0"
   },
   "outputs": [],
   "source": [
    "# Data path will change depending on your system setup.\n",
    "\n",
    "acquisition_data_path = f\"{base_location}2010Q1/Acquisition_2010Q1.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "njzEeyp3uCZ3"
   },
   "source": [
    "#### Loading the Acquisition Data from CSV\n",
    "\n",
    "To load the data we call from `pandas`, `pd.read_csv` which automatically handles loading data from the csv file.  We provide column names, a notification that the file doesn't include headers, and information on what the column separator is `|` in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TSuX8cp_uCZ3"
   },
   "outputs": [],
   "source": [
    "acquisition_df = pd.read_csv(\n",
    "    acquisition_data_path,\n",
    "    names=AcquisitionColumnNames,\n",
    "    header=None,\n",
    "    sep=\"|\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "0C6pRzIquCZ6",
    "outputId": "03c05cdf-01d9-4437-d5af-064f3b0e9076"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LOAN_ID', 'ORIG_CHN', 'Seller.Name', 'ORIG_RT', 'ORIG_AMT', 'ORIG_TRM',\n",
       "       'ORIG_DTE', 'FRST_DTE', 'OLTV', 'OCLTV', 'NUM_BO', 'DTI', 'CSCORE_B',\n",
       "       'FTHB_FLG', 'PURPOSE', 'PROP_TYP', 'NUM_UNIT', 'OCC_STAT', 'STATE',\n",
       "       'ZIP_3', 'MI_PCT', 'Product.Type', 'CSCORE_C', 'MI_TYPE',\n",
       "       'RELOCATION_FLG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acquisition_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJupFzpRuCZ9"
   },
   "source": [
    "#### Loading the Performance Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "aSM-v4WXuCZ-",
    "outputId": "224f82da-104c-4a0d-b8c9-9bafd3e9b3a1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capcolabs/Stevens/Machine-Learning-Algorithms/venv/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "performance_data_path = f\"{base_location}2010Q1/Performance_2010Q1.txt\"\n",
    "\n",
    "performance_df = pd.read_csv(\n",
    "    performance_data_path,\n",
    "    names=PerformanceColumnNames,\n",
    "    header=None,\n",
    "    sep=\"|\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5lE_VMiAuCaA"
   },
   "source": [
    "First thing we note is that this takes longer than the `Acquisitions` data to load, stemming from the fact that for each loan there are multiple monthly data elements loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_CTGeuxquCaY"
   },
   "source": [
    "# Data Modifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = set(performance_df['Delq.Status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan, '40', '55', '64', '27', '24', '28', '88', '89', '52', '87', '42', '53', '56', '67', '99', '57', '86', '49', '93', '36', '90', '43', '20', '26', '74', '9', '84', '75', '66', '95', '17', '41', '37', '11', '25', '58', '31', '50', '81', '5', '63', '71', '97', '47', '35', '38', '85', '65', '16', '62', '70', '32', '18', '29', '83', '23', '12', '14', '69', '82', '79', '4', '10', '54', '19', '91', '45', '46', '92', '34', '94', '22', '78', '33', '2', '72', '30', '15', '61', '76', 'X', '98', '0', '1', '80', '73', '77', '96', '59', '8', '44', '51', '48', '21', '68', '7', '13', '6', '39', '60', '3'}\n"
     ]
    }
   ],
   "source": [
    "print(DS)\n",
    "mapper = {}\n",
    "for ds in DS:\n",
    "    try:\n",
    "        mapper[ds] = int(ds)\n",
    "    except:\n",
    "        mapper[ds] = -1\n",
    "\n",
    "performance_df['Delq.Status'] = performance_df['Delq.Status'].map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22\n",
      " 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46\n",
      " 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70\n",
      " 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94\n",
      " 95 96 97 98 99]\n"
     ]
    }
   ],
   "source": [
    "V, C = np.unique(performance_df['Delq.Status'], return_counts=True)\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping By Loan ID\n",
    "\n",
    "https://stackoverflow.com/questions/15705630/get-the-rows-which-have-the-max-value-in-groups-using-groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = performance_df.groupby(\"LOAN_ID\", sort=True)['Delq.Status'].max()\n",
    "\n",
    "ID_To_Delinq = {}\n",
    "\n",
    "for row in loans.iteritems():\n",
    "    loan_id, delinq = row\n",
    "    ID_To_Delinq[loan_id] = delinq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(row):\n",
    "    return ID_To_Delinq.get(row[\"LOAN_ID\"], -1)\n",
    "\n",
    "acquisition_df['MAX_DELINQ'] = acquisition_df.apply(mapper, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, C = np.unique(acquisition_df['MAX_DELINQ'], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Forclousure Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "FCC_DTE = performance_df['FCC_DTE'].notna()\n",
    "\n",
    "forclosed = performance_df[FCC_DTE]\n",
    "\n",
    "FORECLOSURES = {}\n",
    "\n",
    "for row in forclosed.iterrows():\n",
    "    row = row[1]\n",
    "    FORECLOSURES[row['LOAN_ID']] = row['FCC_DTE']\n",
    "\n",
    "FORCLOSED = set(forclosed['LOAN_ID'])\n",
    "\n",
    "def mapper(row):\n",
    "    # return FORECLOSURES.get(row['LOAN_ID'], \"NO_FCC\")\n",
    "    return int(row['LOAN_ID'] in FORCLOSED)\n",
    "\n",
    "acquisition_df['FCC'] = acquisition_df.apply(mapper, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1}\n"
     ]
    }
   ],
   "source": [
    "print(set(acquisition_df['FCC']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Delinquency Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, C = np.unique(\n",
    "    performance_df['Monthly.Rpt.Prd'], \n",
    "    return_counts=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_date = performance_df['Monthly.Rpt.Prd'] == \"01/01/2015\"\n",
    "next_date   = performance_df['Monthly.Rpt.Prd'] == \"01/01/2016\"\n",
    "\n",
    "date_df = performance_df[actual_date]\n",
    "next_df = performance_df[next_date]\n",
    "\n",
    "Delinquency = {}\n",
    "Next_Delinquency = {}\n",
    "\n",
    "for row in date_df.iterrows():\n",
    "    row = row[1]\n",
    "    Delinquency[row['LOAN_ID']] = ID_To_Delinq.get(row[\"LOAN_ID\"], -1)\n",
    "    \n",
    "for row in next_df.iterrows():\n",
    "    row = row[1]\n",
    "    Next_Delinquency[row['LOAN_ID']] = ID_To_Delinq.get(row['LOAN_ID'], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(row):\n",
    "    return Delinquency.get(row[\"LOAN_ID\"], -1)\n",
    "\n",
    "def next_mapper(row):\n",
    "    return Next_Delinquency.get(row['LOAN_ID'], -1)\n",
    "\n",
    "acquisition_df['DELINQ_DATE'] = acquisition_df.apply(mapper, axis=1)\n",
    "acquisition_df['DELINQ_NEXT'] = acquisition_df.apply(next_mapper, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/capcolabs/Stevens/Machine-Learning-Algorithms/venv/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "delinq = acquisition_df['DELINQ_DATE'] > 0\n",
    "delinq_df = acquisition_df[delinq]\n",
    "\n",
    "print(f\"{len(delinq_df.index)}\")\n",
    "\n",
    "def check_date_range(row):\n",
    "    return row['DELINQ_NEXT'] >= row['DELINQ_DATE']\n",
    "\n",
    "delinq_df['DELINQ_DELTA'] = delinq_df.apply(\n",
    "    check_date_range,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False  |  2219\n",
      "True  |  18084\n"
     ]
    }
   ],
   "source": [
    "V, C = np.unique(delinq_df['DELINQ_DELTA'], return_counts=True)\n",
    "\n",
    "for v, c in zip(V, C):\n",
    "    print(v, \" | \", c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           #xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20038, 4)\n",
      "(20038, 1)\n",
      "(20038, 5)\n",
      "(20038, 4)\n",
      "(20038, 1)\n",
      "Train Number: 18034\n",
      "X_Train: (18034, 4)\n",
      "X_Test: (2004, 4)\n",
      "====================\n",
      "y_Train: (18034, 1)\n",
      "y_Test:  (2004, 1)\n",
      "0.0  |  19397\n",
      "1.0  |  641\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "df = delinq_df\n",
    "\n",
    "DEL_NOTNAN = df[\"DELINQ_DELTA\"].notna()\n",
    "df = df[DEL_NOTNAN]\n",
    "OLTV = df['OLTV'].notna()\n",
    "df = df[OLTV]\n",
    "CS = df['CSCORE_B'].notna()\n",
    "df = df[CS]\n",
    "DTI = df['DTI'].notna()\n",
    "df = df[DTI]\n",
    "\n",
    "credit_score  = np.array(df['CSCORE_B'])\n",
    "loan_to_value = np.array(df['OLTV'])\n",
    "debt_to_income= np.array(df['DTI'])\n",
    "delinq_value  = np.array(df['DELINQ_DATE'])\n",
    "\n",
    "max_delinq    = np.array(df['DELINQ_DELTA'])\n",
    "foreclosed    = np.array(df['FCC'])\n",
    "\n",
    "X = np.array(\n",
    "    [\n",
    "        credit_score, \n",
    "        loan_to_value, \n",
    "        debt_to_income, \n",
    "        delinq_value\n",
    "    ]\n",
    ").transpose()\n",
    "\n",
    "\n",
    "y = np.array([foreclosed]).transpose()\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "Total = np.hstack([X, y])\n",
    "print(Total.shape)\n",
    "np.random.shuffle(Total)\n",
    "\n",
    "X = Total[:, :4]\n",
    "y = Total[:, 4:]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "prop = 0.9\n",
    "train_num = int(prop * len(Total))\n",
    "print(f\"Train Number: {train_num}\")\n",
    "\n",
    "X_train, X_test = X[:train_num], X[train_num:]\n",
    "y_train, y_test = y[:train_num], y[train_num:]\n",
    "\n",
    "print(f\"X_Train: {X_train.shape}\")\n",
    "print(f\"X_Test: {X_test.shape}\")\n",
    "print(\"==\"*10)\n",
    "print(f\"y_Train: {y_train.shape}\")\n",
    "print(f\"y_Test:  {y_test.shape}\")\n",
    "\n",
    "V, C = np.unique(y, return_counts=True)\n",
    "\n",
    "class_weight = {}\n",
    "for v, c in zip(V, C):\n",
    "    prop = c / len(y)\n",
    "    class_weight[v] = 1 - prop\n",
    "    print(v, \" | \", c)\n",
    "\n",
    "class_names = np.unique(y)\n",
    "\n",
    "print(class_names)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "01-Data Loading.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
