{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Deep Dive\n",
    "\n",
    "We will first demonstrate how neural networks work using the Numpy module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from utils import hello_world\n",
    "hello_world()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonlin(x,deriv=False):\n",
    "    if(deriv==True):\n",
    "        return x*(1-x)\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "class SGDNN():\n",
    "    def __init__(self,\n",
    "                 hiddenSize_,\n",
    "                 inputSize_=2,\n",
    "                 outputSize_=3,\n",
    "                 giveSeed_=False,\n",
    "                 seed = 1):\n",
    "        sizeHidden = 20\n",
    "        if giveSeed_:\n",
    "            np.random.seed(seed)\n",
    "        self.syn0 = (2*np.random.random((inputSize_,sizeHidden)) - 1) / np.sqrt(hiddenSize_)\n",
    "        \n",
    "        self.syn1 = (2*np.random.random((sizeHidden,outputSize_)) - 1)/np.sqrt(hiddenSize_)\n",
    "    \n",
    "    \n",
    "    def testPoint(self, X):\n",
    "        l0 = X\n",
    "        l1 = nonlin(np.dot(l0, self.syn0))\n",
    "        l2 = nonlin(np.dot(l1, self.syn1))\n",
    "        return l2\n",
    "    \n",
    "    def trainingAlgorithm(self, Data):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        All = Data\n",
    "        for j in tqdm(range(10000)):\n",
    "            if (j % 100) == 0:\n",
    "                np.random.shuffle(All)\n",
    "            A = All\n",
    "            A = np.split(A, 50)\n",
    "            for a in A:\n",
    "                l0 = a[:,0:2]\n",
    "                l1 = nonlin(np.dot(l0,self.syn0))\n",
    "                l2 = nonlin(np.dot(l1,self.syn1))\n",
    "\n",
    "                l2_error = a[:,2:5] - l2\n",
    "\n",
    "                l2_delta = l2_error*nonlin(l2,deriv=True)\n",
    "\n",
    "                l1_error = l2_delta.dot(self.syn1.T)\n",
    "\n",
    "                l1_delta = l1_error * nonlin(l1,deriv=True)\n",
    "\n",
    "                self.syn1 += 0.1*l1.T.dot(l2_delta)\n",
    "                self.syn0 += 0.1*l0.T.dot(l1_delta)\n",
    "            \n",
    "            # Checking Results every 1000 Epochs\n",
    "            if (j % 1000 ) == 0:\n",
    "                l0 = All[:,0:2]\n",
    "                l1 = nonlin(np.dot(l0, self.syn0))\n",
    "                l2 = nonlin(np.dot(l1, self.syn1))\n",
    "                L2_Error = All[:,2:5] - l2\n",
    "                print(\"Error: \" + str(np.mean(np.abs(L2_Error))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Data\n",
    "\n",
    "To Test the results we create three separate data samples,\n",
    "each in two dimensions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "D1 = np.random.normal((5,5),(1,1),(1000,2))\n",
    "D2 = np.random.normal((-2,-3),(.5,.5),(1000,2))\n",
    "D3 = np.random.normal((2,-6),(.7,.3),(1000,2))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(D1[:,0],D1[:,1])\n",
    "plt.scatter(D2[:,0],D2[:,1])\n",
    "plt.scatter(D3[:,0],D3[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 72/10000 [00:00<00:28, 351.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.0362222770734132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1052/10000 [00:02<00:24, 358.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.0008340653683240229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2059/10000 [00:05<00:21, 365.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.0005505122969865966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 3065/10000 [00:08<00:18, 368.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.00043289948176335614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 4069/10000 [00:11<00:16, 366.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.0003649335866366885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5044/10000 [00:13<00:13, 369.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.00031955585238065473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 6068/10000 [00:16<00:10, 367.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.0002872853991429223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 7066/10000 [00:19<00:08, 353.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.0002623426306231861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8044/10000 [00:22<00:05, 369.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.00024260309854175045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 9071/10000 [00:24<00:02, 373.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.00022650472348792746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:27<00:00, 365.69it/s]\n"
     ]
    }
   ],
   "source": [
    "Points = []\n",
    "X = np.linspace(-5,5,100)\n",
    "Y = np.linspace(-8,8,100)    \n",
    "for x in X:\n",
    "    for y in Y:\n",
    "        Points.append(np.array([x,y]))\n",
    "\n",
    "Data = np.vstack([D1,D2,D3])\n",
    "\n",
    "L1 = np.array([[1,0,0] for i in range(len(D1))])\n",
    "L2 = np.array([[0,1,0] for i in range(len(D2))])\n",
    "L3 = np.array([[0,0,1] for i in range(len(D3))])\n",
    "\n",
    "Label = np.vstack([L1,L2,L3])\n",
    "\n",
    "All = np.hstack([Data,Label])\n",
    "\n",
    "Network = SGDNN(5)\n",
    "Network.trainingAlgorithm(All)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "[-2,-3]\n",
      "Result: [0. 1. 0.]\n",
      "[5,5]\n",
      "Result: [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing\")\n",
    "print(\"[-2,-3]\")\n",
    "res = Network.testPoint(np.array([-2,-3]))\n",
    "print(f\"Result: {np.round(res, 2)}\")\n",
    "\n",
    "print(\"[5,5]\")\n",
    "res = Network.testPoint(np.array([5,5]))\n",
    "print(f\"Result: {np.round(res,2)}\")\n",
    "Vals = []    \n",
    "for p in Points:\n",
    "    Vals.append(Network.testPoint(p))\n",
    "\n",
    "f = open(\"trainedValues.csv\",'w')\n",
    "for i in range(len(Points)):\n",
    "    Line = str(Points[i][0])+\",\"+str(Points[i][1])+\",\"+str(np.argmax(Vals[i])) +\"\\n\"\n",
    "    f.write(Line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Model\n",
    "\n",
    "To start let's recreate our NumPy based model from above.  Using `sigmoid` activation and `mean squared error` to start with.  The layers will be:\n",
    "\n",
    "- Input\n",
    "- Hidden Layer\n",
    "- Output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input(\n",
    "    shape=[2]\n",
    ")\n",
    "\n",
    "hidden_layer = tf.keras.layers.Dense(32, activation='sigmoid')(input_layer)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(3, activation='sigmoid')(hidden_layer)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=input_layer,\n",
    "    outputs=output_layer,\n",
    "    name='initial_model'\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model, \n",
    "    'my_first_model.png',\n",
    "    show_shapes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.MSE,\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions\n",
    ">Images and Code Taken from https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23\n",
    "\n",
    "---\n",
    "![](imgs/losses.png)\n",
    "> FROM: https://heartbeat.fritz.ai/5-regression-loss-functions-all-machine-learners-should-know-4fb140e9d4b0\n",
    "---\n",
    "\n",
    "### Mean Square Error\n",
    "\n",
    "From Wikipedia:\n",
    ">In statistics, the mean squared error (MSE) of an estimator (of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors — that is, the average squared difference between the estimated values and what is estimated. MSE is a risk function, corresponding to the expected value of the squared error loss. The fact that MSE is almost always strictly positive (and not zero) is because of randomness or because the estimator does not account for information that could produce a more accurate estimate.\n",
    "\n",
    "- https://www.freecodecamp.org/news/machine-learning-mean-squared-error-regression-line-c7dde9a26b93/\n",
    "\n",
    "![](imgs/mse.png)\n",
    "\n",
    "```\n",
    "import numpy as npy_hat = np.array([0.000, 0.166, 0.333])\n",
    "y_true = np.array([0.000, 0.254, 0.998])def rmse(predictions, targets):\n",
    "    differences = predictions - targets\n",
    "    differences_squared = differences ** 2\n",
    "    mean_of_differences_squared = differences_squared.mean()\n",
    "    rmse_val = np.sqrt(mean_of_differences_squared)\n",
    "    return rmse_valprint(\"d is: \" + str([\"%.8f\" % elem for elem in y_hat]))\n",
    "print(\"p is: \" + str([\"%.8f\" % elem for elem in y_true]))rmse_val = rmse(y_hat, y_true)\n",
    "print(\"rms error is: \" + str(rmse_val))\n",
    "```\n",
    "\n",
    "\n",
    "### Mean Absolute Error\n",
    "\n",
    "From Wikipedia:https://en.wikipedia.org/wiki/Mean_absolute_error\n",
    "\n",
    ">In statistics, mean absolute error (MAE) is a measure of difference between two continuous variables. Assume X and Y are variables of paired observations that express the same phenomenon. Examples of Y versus X include comparisons of predicted versus observed, subsequent time versus initial time, and one technique of measurement versus an alternative technique of measurement. Consider a scatter plot of n points, where point i has coordinates (xi, yi)... Mean Absolute Error (MAE) is the average vertical distance between each point and the identity line. MAE is also the average horizontal distance between each point and the identity line. \n",
    "\n",
    "![](imgs/mae.png)\n",
    "\n",
    "```\n",
    "import numpy as npy_hat = np.array([0.000, 0.166, 0.333])\n",
    "y_true = np.array([0.000, 0.254, 0.998])\n",
    "\n",
    "print(\"d is: \" + str([\"%.8f\" % elem for elem in y_hat]))\n",
    "print(\"p is: \" + str([\"%.8f\" % elem for elem in y_true]))\n",
    "\n",
    "def mae(predictions, targets):\n",
    "    differences = predictions - targets\n",
    "    absolute_differences = np.absolute(differences)\n",
    "    mean_absolute_differences = absolute_differences.mean()\n",
    "    return mean_absolute_differencesmae_val = mae(y_hat, y_true)\n",
    "print (\"mae error is: \" + str(mae_val))\n",
    "```\n",
    "\n",
    "\n",
    "### Cross Entropy Loss\n",
    "\n",
    ">In information theory, the cross entropy between two probability distributions p {\\displaystyle p} p and q {\\displaystyle q} q over the same underlying set of events measures the average number of bits needed to identify an event drawn from the set if a coding scheme used for the set is optimized for an estimated probability distribution q {\\displaystyle q} q, rather than the true distribution p {\\displaystyle p} p. \n",
    "\n",
    "Resources:\n",
    "- https://gombru.github.io/2018/05/23/cross_entropy_loss/\n",
    "\n",
    "\n",
    "![](imgs/cel.png)\n",
    "\n",
    "```\n",
    "import numpy as nppredictions = np.array([[0.25,0.25,0.25,0.25],\n",
    "                        [0.01,0.01,0.01,0.96]])\n",
    "targets = np.array([[0,0,0,1],\n",
    "                   [0,0,0,1]])def cross_entropy(predictions, targets, epsilon=1e-10):\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    ce_loss = -np.sum(np.sum(targets * np.log(predictions + 1e-5)))/N\n",
    "    return ce_losscross_entropy_loss = cross_entropy(predictions, targets)\n",
    "print (\"Cross entropy loss is: \" + str(cross_entropy_loss))\n",
    "```\n",
    "\n",
    "Resources:\n",
    "- https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryCrossentropy\n",
      "CategoricalCrossentropy\n",
      "CategoricalHinge\n",
      "CosineSimilarity\n",
      "Hinge\n",
      "Huber\n",
      "KLD\n",
      "KLDivergence\n",
      "LogCosh\n",
      "Loss\n",
      "MAE\n",
      "MAPE\n",
      "MSE\n",
      "MSLE\n",
      "MeanAbsoluteError\n",
      "MeanAbsolutePercentageError\n",
      "MeanSquaredError\n",
      "MeanSquaredLogarithmicError\n",
      "Poisson\n",
      "Reduction\n",
      "SparseCategoricalCrossentropy\n",
      "SquaredHinge\n",
      "binary_crossentropy\n",
      "categorical_crossentropy\n",
      "categorical_hinge\n",
      "cosine_similarity\n",
      "deserialize\n",
      "get\n",
      "hinge\n",
      "kld\n",
      "kullback_leibler_divergence\n",
      "logcosh\n",
      "mae\n",
      "mape\n",
      "mean_absolute_error\n",
      "mean_absolute_percentage_error\n",
      "mean_squared_error\n",
      "mean_squared_logarithmic_error\n",
      "mse\n",
      "msle\n",
      "poisson\n",
      "serialize\n",
      "sparse_categorical_crossentropy\n",
      "squared_hinge\n"
     ]
    }
   ],
   "source": [
    "for d in dir(tf.keras.losses):\n",
    "    if d[0] == \"_\":\n",
    "        continue\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deserialize\n",
      "elu\n",
      "exponential\n",
      "get\n",
      "hard_sigmoid\n",
      "linear\n",
      "relu\n",
      "selu\n",
      "serialize\n",
      "sigmoid\n",
      "softmax\n",
      "softplus\n",
      "softsign\n",
      "tanh\n"
     ]
    }
   ],
   "source": [
    "for d in dir(tf.keras.activations):\n",
    "    if d[0]==\"_\":\n",
    "        continue\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC\n",
      "Accuracy\n",
      "BinaryAccuracy\n",
      "BinaryCrossentropy\n",
      "CategoricalAccuracy\n",
      "CategoricalCrossentropy\n",
      "CategoricalHinge\n",
      "CosineSimilarity\n",
      "FalseNegatives\n",
      "FalsePositives\n",
      "Hinge\n",
      "KLD\n",
      "KLDivergence\n",
      "LogCoshError\n",
      "MAE\n",
      "MAPE\n",
      "MSE\n",
      "MSLE\n",
      "Mean\n",
      "MeanAbsoluteError\n",
      "MeanAbsolutePercentageError\n",
      "MeanIoU\n",
      "MeanRelativeError\n",
      "MeanSquaredError\n",
      "MeanSquaredLogarithmicError\n",
      "MeanTensor\n",
      "Metric\n",
      "Poisson\n",
      "Precision\n",
      "Recall\n",
      "RootMeanSquaredError\n",
      "SensitivityAtSpecificity\n",
      "SparseCategoricalAccuracy\n",
      "SparseCategoricalCrossentropy\n",
      "SparseTopKCategoricalAccuracy\n",
      "SpecificityAtSensitivity\n",
      "SquaredHinge\n",
      "Sum\n",
      "TopKCategoricalAccuracy\n",
      "TrueNegatives\n",
      "TruePositives\n",
      "binary_accuracy\n",
      "binary_crossentropy\n",
      "categorical_accuracy\n",
      "categorical_crossentropy\n",
      "deserialize\n",
      "get\n",
      "hinge\n",
      "kld\n",
      "kullback_leibler_divergence\n",
      "mae\n",
      "mape\n",
      "mean_absolute_error\n",
      "mean_absolute_percentage_error\n",
      "mean_squared_error\n",
      "mean_squared_logarithmic_error\n",
      "mse\n",
      "msle\n",
      "poisson\n",
      "serialize\n",
      "sparse_categorical_accuracy\n",
      "sparse_categorical_crossentropy\n",
      "sparse_top_k_categorical_accuracy\n",
      "squared_hinge\n",
      "top_k_categorical_accuracy\n"
     ]
    }
   ],
   "source": [
    "for d in dir(tf.keras.metrics):\n",
    "    if d[0] == \"_\":\n",
    "        continue\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"initial_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                96        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_layer = tf.keras.layers.Input(\n",
    "    shape=[2]\n",
    ")\n",
    "\n",
    "hidden_layer = tf.keras.layers.Dense(32, activation='relu')(input_layer)\n",
    "\n",
    "output_layer = tf.keras.layers.Dense(3, activation='relu')(hidden_layer)\n",
    "\n",
    "model = tf.keras.Model(\n",
    "    inputs=input_layer,\n",
    "    outputs=output_layer,\n",
    "    name='initial_model'\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    model, \n",
    "    'my_first_model.png',\n",
    "    show_shapes=True\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.MSE,\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "Resources:\n",
    "- https://www.tensorflow.org/guide/keras/rnn\n",
    "\n",
    "Taken from Wikipedia:\n",
    "\n",
    ">A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes form a directed graph along a temporal sequence. This allows it to exhibit temporal dynamic behavior. Unlike feedforward neural networks, RNNs can use their internal state (memory) to process sequences of inputs. This makes them applicable to tasks such as unsegmented, connected handwriting recognition[1] or speech recognition.[2][3]\n",
    "\n",
    ">The term \"recurrent neural network\" is used indiscriminately to refer to two broad classes of networks with a similar general structure, where one is finite impulse and the other is infinite impulse. Both classes of networks exhibit temporal dynamic behavior.[4] A finite impulse recurrent network is a directed acyclic graph that can be unrolled and replaced with a strictly feedforward neural network, while an infinite impulse recurrent network is a directed cyclic graph that can not be unrolled.\n",
    "\n",
    ">Both finite impulse and infinite impulse recurrent networks can have additional stored state, and the storage can be under direct control by the neural network. The storage can also be replaced by another network or graph, if that incorporates time delays or has feedback loops. Such controlled states are referred to as gated state or gated memory, and are part of long short-term memory networks (LSTMs) and gated recurrent units. \n",
    "\n",
    "Other Resources:\n",
    "\n",
    "- https://medium.com/@jianqiangma/all-about-recurrent-neural-networks-9e5ae2936f6e\n",
    "\n",
    "## Long-Short Term Memory (LSTM)\n",
    "\n",
    ">Long short-term memory (LSTM) is an artificial recurrent neural network (RNN) architecture[1] used in the field of deep learning. Unlike standard feedforward neural networks, LSTM has feedback connections. It can not only process single data points (such as images), but also entire sequences of data (such as speech or video). For example, LSTM is applicable to tasks such as unsegmented, connected handwriting recognition[2] or speech recognition.[3][4] Bloomberg Business Week wrote: \"These powers make LSTM arguably the most commercial AI achievement, used for everything from predicting diseases to composing music.\"[5]\n",
    "\n",
    ">A common LSTM unit is composed of a cell, an input gate, an output gate and a forget gate. The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell.\n",
    "\n",
    ">LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series. LSTMs were developed to deal with the exploding and vanishing gradient problems that can be encountered when training traditional RNNs. Relative insensitivity to gap length is an advantage of LSTM over RNNs, hidden Markov models and other sequence learning methods in numerous applications.[citation needed] \n",
    "\n",
    "![](imgs/lstm.svg)\n",
    "\n",
    "## Gated Recurrent Unit (GRU)\n",
    "\n",
    ">Gated recurrent units (GRUs) are a gating mechanism in recurrent neural networks, introduced in 2014 by Kyunghyun Cho et al.[1] The GRU is like a long short-term memory (LSTM) with forget gate[2] but has fewer parameters than LSTM, as it lacks an output gate.[3] GRU's performance on certain tasks of polyphonic music modeling and speech signal modeling was found to be similar to that of LSTM. GRUs have been shown to exhibit even better performance on certain smaller datasets.[4]\n",
    "\n",
    ">However, as shown by Gail Weiss & Yoav Goldberg & Eran Yahav, the LSTM is \"strictly stronger\" than the GRU as it can easily perform unbounded counting, while the GRU cannot.[5] That's why the GRU fails to learn simple languages that are learnable by the LSTM.[5]\n",
    "\n",
    ">Similarly, as shown by Denny Britz & Anna Goldie & Minh-Thang Luong & Quoc Le of Google Brain, LSTM cells consistently outperform GRU cells in \"the first large-scale analysis of architecture variations for Neural Machine Translation.\"[6] \n",
    "\n",
    "![](imgs/gru.svg)\n",
    "\n",
    "\n",
    "### Building LSTM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 164,106\n",
      "Trainable params: 164,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "model.add(tf.keras.layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(tf.keras.layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 10 units and softmax activation.\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outputs and states\n",
    "\n",
    "From: https://www.tensorflow.org/guide/keras/rnn#outputs_and_states\n",
    "\n",
    "By default, the output of a RNN layer contain a single vector per sample. This vector is the RNN cell output corresponding to the last timestep, containing information about the entire input sequence. The shape of this output is (batch_size, units) where units corresponds to the units argument passed to the layer's constructor.\n",
    "\n",
    "A RNN layer can also return the entire sequence of outputs for each sample (one vector per timestep per sample), if you set return_sequences=True. The shape of this output is (batch_size, timesteps, units)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 64)          64000     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, None, 256)         247296    \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 128)               49280     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 361,866\n",
      "Trainable params: 361,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
    "model.add(tf.keras.layers.GRU(256, return_sequences=True))\n",
    "\n",
    "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
    "model.add(tf.keras.layers.SimpleRNN(128))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, a RNN layer can return its final internal state(s). The returned states can be used to resume the RNN execution later, or to initialize another RNN. This setting is commonly used in the encoder-decoder sequence-to-sequence model, where the encoder final state is used as the initial state of the decoder.\n",
    "\n",
    "To configure a RNN layer to return its internal state, set the return_state parameter to True when creating the layer. Note that LSTM has 2 state tensors, but GRU only has one.\n",
    "\n",
    "To configure the initial state of the layer, just call the layer with additional keyword argument initial_state. Note that the shape of the state needs to match the unit size of the layer, like in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 64)     64000       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, None, 64)     128000      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "encoder (LSTM)                  [(None, 64), (None,  33024       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "decoder (LSTM)                  (None, 64)           33024       embedding_3[0][0]                \n",
      "                                                                 encoder[0][1]                    \n",
      "                                                                 encoder[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           650         decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 258,698\n",
      "Trainable params: 258,698\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_vocab = 1000\n",
    "decoder_vocab = 2000\n",
    "\n",
    "encoder_input = tf.keras.layers.Input(shape=(None, ))\n",
    "encoder_embedded = tf.keras.layers.Embedding(input_dim=encoder_vocab, output_dim=64)(encoder_input)\n",
    "\n",
    "# Return states in addition to output\n",
    "output, state_h, state_c = tf.keras.layers.LSTM(\n",
    "    64, return_state=True, name='encoder')(encoder_embedded)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "decoder_input = tf.keras.layers.Input(shape=(None, ))\n",
    "decoder_embedded = tf.keras.layers.Embedding(input_dim=decoder_vocab, output_dim=64)(decoder_input)\n",
    "\n",
    "# Pass the 2 states to a new LSTM layer, as initial state\n",
    "decoder_output = tf.keras.layers.LSTM(\n",
    "    64, name='decoder')(decoder_embedded, initial_state=encoder_state)\n",
    "output = tf.keras.layers.Dense(10, activation='softmax')(decoder_output)\n",
    "\n",
    "model = tf.keras.Model([encoder_input, decoder_input], output)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-batch statefulness\n",
    "\n",
    "From: https://www.tensorflow.org/guide/keras/rnn#cross-batch_statefulness\n",
    "\n",
    "When processing very long sequences (possibly infinite), you may want to use the pattern of cross-batch statefulness.\n",
    "\n",
    "Normally, the internal state of a RNN layer is reset every time it sees a new batch (i.e. every sample seen by the layer is assume to be independent from the past). The layer will only maintain a state while processing a given sample.\n",
    "\n",
    "If you have very long sequences though, it is useful to break them into shorter sequences, and to feed these shorter sequences sequentially into a RNN layer without resetting the layer's state. That way, the layer can retain information about the entirety of the sequence, even though it's only seeing one sub-sequence at a time.\n",
    "\n",
    "You can do this by setting stateful=True in the constructor.\n",
    "\n",
    "If you have a sequence s = [t0, t1, ... t1546, t1547], you would split it into e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "\n",
    "lstm_layer = tf.keras.layers.LSTM(64, stateful=True)\n",
    "output = lstm_layer(paragraph1)\n",
    "output = lstm_layer(paragraph2)\n",
    "output = lstm_layer(paragraph3)\n",
    "\n",
    "# reset_states() will reset the cached state to the original initial_state.\n",
    "# If no initial_state was provided, zero-states will be used by default.\n",
    "lstm_layer.reset_states()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building GRU Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-Directional Recurrent Neural Networks\n",
    "\n",
    ">Bi-directional RNNs use a finite sequence to predict or label each element of the sequence based on the element's past and future contexts. This is done by concatenating the outputs of two RNNs, one processing the sequence from left to right, the other one from right to left. The combined outputs are the predictions of the teacher-given target signals. This technique proved to be especially useful when combined with LSTM RNNs.[47][48]\n",
    "\n",
    "- https://www.sciencedirect.com/science/article/abs/pii/S0893608005001206?via%3Dihub\n",
    "\n",
    "\n",
    "###  Bidirectional RNNs\n",
    "\n",
    "From: https://www.tensorflow.org/guide/keras/rnn#bidirectional_rnns\n",
    "\n",
    "For sequences other than time series (e.g. text), it is often the case that a RNN model can perform better if it not only processes sequence from start to end, but also backwards. For example, to predict the next word in a sentence, it is often useful to have the context around the word, not only just the words that come before it.\n",
    "\n",
    "Keras provides an easy API for you to build such bidirectional RNNs: the `tf.keras.layers.Bidirectional` wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional (Bidirectional (None, 5, 128)            38400     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                41216     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 80,266\n",
      "Trainable params: 80,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Bidirectional(\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True), \n",
    "    input_shape=(5, 10))\n",
    ")\n",
    "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
